{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyOvIRWZZZi6"
   },
   "source": [
    "## Import's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jD7Xt1K2tNK4"
   },
   "outputs": [],
   "source": [
    "# Базовые\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# Предобработка и пайплайны\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as SkDecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data from Don’tGetKicked competition.Design train/validation/test split.\n",
    "\n",
    "Use the \"PurchDate\" field to split, test must be later in time than validation, same goes for validation and train: train.PurchDate < valid.PurchDate < test.PurchDate.\n",
    "\n",
    "Use the first 33% of the data for the training, the last 33% of the data for the test, and the middle 33% for the validation set. Don't use the test dataset until the end!\n",
    "\n",
    "Use LabelEncoder or OneHotEncoder from sklearn to preprocess categorical variables. Be careful with data leakage (fit Encoder to training and apply to validation & test). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FKBqs7dZcUQ"
   },
   "source": [
    "### - Download data from Don’tGetKicked competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4mhKn6GhuNxP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "lMX_ad8vub8H",
    "outputId": "25d02369-ce80-47c7-e8ab-35a3836b58b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>...</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>MAZDA</td>\n",
       "      <td>MAZDA3</td>\n",
       "      <td>i</td>\n",
       "      <td>4D SEDAN I</td>\n",
       "      <td>...</td>\n",
       "      <td>11597.0</td>\n",
       "      <td>12409.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21973</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>1500 RAM PICKUP 2WD</td>\n",
       "      <td>ST</td>\n",
       "      <td>QUAD CAB 4.7L SLT</td>\n",
       "      <td>...</td>\n",
       "      <td>11374.0</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>STRATUS V6</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN SXT FFV</td>\n",
       "      <td>...</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>8702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>NEON</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>5518.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FOCUS</td>\n",
       "      <td>ZX3</td>\n",
       "      <td>2D COUPE ZX3</td>\n",
       "      <td>...</td>\n",
       "      <td>6739.0</td>\n",
       "      <td>7911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  IsBadBuy  PurchDate Auction  VehYear  VehicleAge   Make  \\\n",
       "0      1         0  12/7/2009   ADESA     2006           3  MAZDA   \n",
       "1      2         0  12/7/2009   ADESA     2004           5  DODGE   \n",
       "2      3         0  12/7/2009   ADESA     2005           4  DODGE   \n",
       "3      4         0  12/7/2009   ADESA     2004           5  DODGE   \n",
       "4      5         0  12/7/2009   ADESA     2005           4   FORD   \n",
       "\n",
       "                 Model Trim           SubModel  ...  \\\n",
       "0               MAZDA3    i         4D SEDAN I  ...   \n",
       "1  1500 RAM PICKUP 2WD   ST  QUAD CAB 4.7L SLT  ...   \n",
       "2           STRATUS V6  SXT   4D SEDAN SXT FFV  ...   \n",
       "3                 NEON  SXT           4D SEDAN  ...   \n",
       "4                FOCUS  ZX3       2D COUPE ZX3  ...   \n",
       "\n",
       "  MMRCurrentRetailAveragePrice MMRCurrentRetailCleanPrice  PRIMEUNIT AUCGUART  \\\n",
       "0                      11597.0                    12409.0        NaN      NaN   \n",
       "1                      11374.0                    12791.0        NaN      NaN   \n",
       "2                       7146.0                     8702.0        NaN      NaN   \n",
       "3                       4375.0                     5518.0        NaN      NaN   \n",
       "4                       6739.0                     7911.0        NaN      NaN   \n",
       "\n",
       "   BYRNO VNZIP1 VNST VehBCost  IsOnlineSale  WarrantyCost  \n",
       "0  21973  33619   FL   7100.0             0          1113  \n",
       "1  19638  33619   FL   7600.0             0          1053  \n",
       "2  19638  33619   FL   4900.0             0          1389  \n",
       "3  19638  33619   FL   4100.0             0           630  \n",
       "4  19638  33619   FL   4000.0             0          1020  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ImMBoHGZe6s"
   },
   "source": [
    "### - Design the train/validation/test split. Use the \"PurchDate\" field for the split, test must be later than validation, same for validation and train: train.PurchDate < valid.PurchDate < test.PurchDate. Use the first 1/3 of dates for the train, the last 1/3 of dates for the test, and the middle 1/3 for the validation set. Don’t use the test dataset until the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3srVEVIyvpij"
   },
   "outputs": [],
   "source": [
    "def split_train_val_test_date(df: pd.DataFrame, date_col: str = \"PurchDate\", y_col: str = \"IsBadBuy\") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "  d = df.copy()\n",
    "  d[date_col] = pd.to_datetime(d[date_col])\n",
    "\n",
    "  uniq_dates = np.array(sorted(d[date_col].unique()))\n",
    "  n = len(uniq_dates)\n",
    "\n",
    "  a = n // 3\n",
    "  b = 2 * n // 3\n",
    "\n",
    "  d_train = uniq_dates[:a]\n",
    "  d_valid = uniq_dates[a:b]\n",
    "  d_test = uniq_dates[b:]\n",
    "\n",
    "  train_df = d[d[date_col].isin(d_train)].sort_values(date_col)\n",
    "  valid_df = d[d[date_col].isin(d_valid)].sort_values(date_col)\n",
    "  test_df = d[d[date_col].isin(d_test)].sort_values(date_col)\n",
    "\n",
    "  return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yEOappAujplO"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = split_train_val_test_date(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtvnlpFWjXpe",
    "outputId": "30b5260a-a760-4217-a3e9-d902f4651ae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"PurchDate\"].max() < valid_df[\"PurchDate\"].min() < test_df[\"PurchDate\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LZNEO6rAlaYk",
    "outputId": "38c03673-2f25-4abc-8c1a-6a52c6c0f513"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>...</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32387</th>\n",
       "      <td>32409</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>FORD</td>\n",
       "      <td>TAURUS 3.0L V6 EFI</td>\n",
       "      <td>SES</td>\n",
       "      <td>4D SEDAN SES DURATEC</td>\n",
       "      <td>...</td>\n",
       "      <td>4139.0</td>\n",
       "      <td>5351.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22916</td>\n",
       "      <td>80022</td>\n",
       "      <td>CO</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32386</th>\n",
       "      <td>32408</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>TRAILBLAZER EXT 4WD</td>\n",
       "      <td>LS</td>\n",
       "      <td>4D SUV 4.2L</td>\n",
       "      <td>...</td>\n",
       "      <td>10438.0</td>\n",
       "      <td>12158.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22916</td>\n",
       "      <td>80022</td>\n",
       "      <td>CO</td>\n",
       "      <td>8180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32385</th>\n",
       "      <td>32407</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>STRATUS 4C 2.4L I4 M</td>\n",
       "      <td>SE</td>\n",
       "      <td>4D SEDAN SE</td>\n",
       "      <td>...</td>\n",
       "      <td>4169.0</td>\n",
       "      <td>5114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3453</td>\n",
       "      <td>80022</td>\n",
       "      <td>CO</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32384</th>\n",
       "      <td>32406</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FREESTAR FWD V6 3.9L</td>\n",
       "      <td>SES</td>\n",
       "      <td>4D PASSENGER 3.9L SES</td>\n",
       "      <td>...</td>\n",
       "      <td>5801.0</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22916</td>\n",
       "      <td>80022</td>\n",
       "      <td>CO</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32383</th>\n",
       "      <td>32405</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>PONTIAC</td>\n",
       "      <td>GRAND PRIX 3.8L V6 S</td>\n",
       "      <td>Bas</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>8017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22916</td>\n",
       "      <td>80022</td>\n",
       "      <td>CO</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56842</th>\n",
       "      <td>56870</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>FORD</td>\n",
       "      <td>EXPLORER 2WD V6 4.0L</td>\n",
       "      <td>XLT</td>\n",
       "      <td>4D SUV 4.0L XLT</td>\n",
       "      <td>...</td>\n",
       "      <td>8813.0</td>\n",
       "      <td>10205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23359</td>\n",
       "      <td>92504</td>\n",
       "      <td>CA</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56843</th>\n",
       "      <td>56871</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>AVENGER 4C 2.4L I4 S</td>\n",
       "      <td>SE</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>9753.0</td>\n",
       "      <td>10571.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23359</td>\n",
       "      <td>92504</td>\n",
       "      <td>CA</td>\n",
       "      <td>7855.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56844</th>\n",
       "      <td>56872</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>PT CRUISER 2.4L I4 S</td>\n",
       "      <td>Bas</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>7169.0</td>\n",
       "      <td>8141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23359</td>\n",
       "      <td>92504</td>\n",
       "      <td>CA</td>\n",
       "      <td>6140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56834</th>\n",
       "      <td>56862</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>AVENGER 4C 2.4L I4 S</td>\n",
       "      <td>SE</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>11777.0</td>\n",
       "      <td>12505.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23359</td>\n",
       "      <td>92504</td>\n",
       "      <td>CA</td>\n",
       "      <td>7755.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53442</th>\n",
       "      <td>53470</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>PT CRUISER 2.4L I4 S</td>\n",
       "      <td>Bas</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>10403.0</td>\n",
       "      <td>10801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99761</td>\n",
       "      <td>74135</td>\n",
       "      <td>OK</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23059 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RefId  IsBadBuy  PurchDate  Auction  VehYear  VehicleAge       Make  \\\n",
       "32387  32409         0 2009-01-05  MANHEIM     2004           5       FORD   \n",
       "32386  32408         0 2009-01-05  MANHEIM     2006           3  CHEVROLET   \n",
       "32385  32407         0 2009-01-05  MANHEIM     2004           5      DODGE   \n",
       "32384  32406         0 2009-01-05  MANHEIM     2005           4       FORD   \n",
       "32383  32405         0 2009-01-05  MANHEIM     2005           4    PONTIAC   \n",
       "...      ...       ...        ...      ...      ...         ...        ...   \n",
       "56842  56870         1 2009-09-01  MANHEIM     2004           5       FORD   \n",
       "56843  56871         0 2009-09-01  MANHEIM     2008           1      DODGE   \n",
       "56844  56872         0 2009-09-01  MANHEIM     2007           2   CHRYSLER   \n",
       "56834  56862         0 2009-09-01  MANHEIM     2008           1      DODGE   \n",
       "53442  53470         0 2009-09-01    OTHER     2008           1   CHRYSLER   \n",
       "\n",
       "                      Model Trim               SubModel  ...  \\\n",
       "32387    TAURUS 3.0L V6 EFI  SES   4D SEDAN SES DURATEC  ...   \n",
       "32386   TRAILBLAZER EXT 4WD   LS            4D SUV 4.2L  ...   \n",
       "32385  STRATUS 4C 2.4L I4 M   SE            4D SEDAN SE  ...   \n",
       "32384  FREESTAR FWD V6 3.9L  SES  4D PASSENGER 3.9L SES  ...   \n",
       "32383  GRAND PRIX 3.8L V6 S  Bas               4D SEDAN  ...   \n",
       "...                     ...  ...                    ...  ...   \n",
       "56842  EXPLORER 2WD V6 4.0L  XLT        4D SUV 4.0L XLT  ...   \n",
       "56843  AVENGER 4C 2.4L I4 S   SE               4D SEDAN  ...   \n",
       "56844  PT CRUISER 2.4L I4 S  Bas               4D SEDAN  ...   \n",
       "56834  AVENGER 4C 2.4L I4 S   SE               4D SEDAN  ...   \n",
       "53442  PT CRUISER 2.4L I4 S  Bas               4D SEDAN  ...   \n",
       "\n",
       "      MMRCurrentRetailAveragePrice MMRCurrentRetailCleanPrice  PRIMEUNIT  \\\n",
       "32387                       4139.0                     5351.0        NaN   \n",
       "32386                      10438.0                    12158.0        NaN   \n",
       "32385                       4169.0                     5114.0        NaN   \n",
       "32384                       5801.0                     6949.0        NaN   \n",
       "32383                       6670.0                     8017.0        NaN   \n",
       "...                            ...                        ...        ...   \n",
       "56842                       8813.0                    10205.0        NaN   \n",
       "56843                       9753.0                    10571.0        NaN   \n",
       "56844                       7169.0                     8141.0        NaN   \n",
       "56834                      11777.0                    12505.0        NaN   \n",
       "53442                      10403.0                    10801.0        NaN   \n",
       "\n",
       "      AUCGUART  BYRNO VNZIP1 VNST VehBCost  IsOnlineSale  WarrantyCost  \n",
       "32387      NaN  22916  80022   CO   4900.0             0           825  \n",
       "32386      NaN  22916  80022   CO   8180.0             0          1703  \n",
       "32385      NaN   3453  80022   CO   4250.0             0          1155  \n",
       "32384      NaN  22916  80022   CO   6160.0             0           941  \n",
       "32383      NaN  22916  80022   CO   6010.0             0          1974  \n",
       "...        ...    ...    ...  ...      ...           ...           ...  \n",
       "56842      NaN  23359  92504   CA   7520.0             0          1155  \n",
       "56843      NaN  23359  92504   CA   7855.0             0          1020  \n",
       "56844      NaN  23359  92504   CA   6140.0             0          1215  \n",
       "56834      NaN  23359  92504   CA   7755.0             0          1020  \n",
       "53442      NaN  99761  74135   OK   6800.0             0           975  \n",
       "\n",
       "[23059 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>...</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69724</th>\n",
       "      <td>69756</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-02</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>300 2.7L V6 MPI</td>\n",
       "      <td>Bas</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>11680.0</td>\n",
       "      <td>13502.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21053</td>\n",
       "      <td>85226</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9795.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50519</th>\n",
       "      <td>50547</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-02</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>CARAVAN FWD 4C 2.4L</td>\n",
       "      <td>SE</td>\n",
       "      <td>MINIVAN 2.4L</td>\n",
       "      <td>...</td>\n",
       "      <td>7299.0</td>\n",
       "      <td>8923.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20833</td>\n",
       "      <td>78219</td>\n",
       "      <td>TX</td>\n",
       "      <td>6150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50518</th>\n",
       "      <td>50546</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-02</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>PT CRUISER 2.4L I4 S</td>\n",
       "      <td>Lim</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>8126.0</td>\n",
       "      <td>9545.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18822</td>\n",
       "      <td>78219</td>\n",
       "      <td>TX</td>\n",
       "      <td>6735.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50517</th>\n",
       "      <td>50545</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-02</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>MONTERO 4WD V6 3.5L</td>\n",
       "      <td>Lim</td>\n",
       "      <td>4D SPORT UTILITY LIMITED</td>\n",
       "      <td>...</td>\n",
       "      <td>8068.0</td>\n",
       "      <td>9086.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18822</td>\n",
       "      <td>78219</td>\n",
       "      <td>TX</td>\n",
       "      <td>7135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-02</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>PONTIAC</td>\n",
       "      <td>GRAND AM V6 3.4L V6</td>\n",
       "      <td>SE</td>\n",
       "      <td>4D SEDAN SE1</td>\n",
       "      <td>...</td>\n",
       "      <td>3939.0</td>\n",
       "      <td>5173.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19619</td>\n",
       "      <td>20166</td>\n",
       "      <td>VA</td>\n",
       "      <td>5685.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48619</th>\n",
       "      <td>48643</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>PT CRUISER</td>\n",
       "      <td>Tou</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>9005.0</td>\n",
       "      <td>10247.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16044</td>\n",
       "      <td>17545</td>\n",
       "      <td>PA</td>\n",
       "      <td>5785.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48620</th>\n",
       "      <td>48644</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>STRATUS V6</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>8624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16044</td>\n",
       "      <td>17545</td>\n",
       "      <td>PA</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621</th>\n",
       "      <td>48645</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>MALIBU MAXX V6</td>\n",
       "      <td>LS</td>\n",
       "      <td>4D SEDAN LS</td>\n",
       "      <td>...</td>\n",
       "      <td>7893.0</td>\n",
       "      <td>9339.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16044</td>\n",
       "      <td>17545</td>\n",
       "      <td>PA</td>\n",
       "      <td>7460.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50880</th>\n",
       "      <td>50908</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>NEON</td>\n",
       "      <td>Bas</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>4310.0</td>\n",
       "      <td>5078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18822</td>\n",
       "      <td>78219</td>\n",
       "      <td>TX</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21025</th>\n",
       "      <td>21040</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>MAGNUM V6</td>\n",
       "      <td>SE</td>\n",
       "      <td>WAGON 2.7L</td>\n",
       "      <td>...</td>\n",
       "      <td>13467.0</td>\n",
       "      <td>15805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17212</td>\n",
       "      <td>75236</td>\n",
       "      <td>TX</td>\n",
       "      <td>8050.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24104 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RefId  IsBadBuy  PurchDate  Auction  VehYear  VehicleAge        Make  \\\n",
       "69724  69756         0 2009-09-02    ADESA     2006           3    CHRYSLER   \n",
       "50519  50547         0 2009-09-02  MANHEIM     2006           3       DODGE   \n",
       "50518  50546         0 2009-09-02  MANHEIM     2006           3    CHRYSLER   \n",
       "50517  50545         0 2009-09-02  MANHEIM     2002           7  MITSUBISHI   \n",
       "484      485         0 2009-09-02    ADESA     2004           5     PONTIAC   \n",
       "...      ...       ...        ...      ...      ...         ...         ...   \n",
       "48619  48643         1 2010-04-30  MANHEIM     2006           4    CHRYSLER   \n",
       "48620  48644         0 2010-04-30  MANHEIM     2006           4       DODGE   \n",
       "48621  48645         0 2010-04-30  MANHEIM     2004           6   CHEVROLET   \n",
       "50880  50908         0 2010-04-30  MANHEIM     2002           8       DODGE   \n",
       "21025  21040         0 2010-04-30  MANHEIM     2007           3       DODGE   \n",
       "\n",
       "                      Model Trim                  SubModel  ...  \\\n",
       "69724       300 2.7L V6 MPI  Bas                  4D SEDAN  ...   \n",
       "50519   CARAVAN FWD 4C 2.4L   SE              MINIVAN 2.4L  ...   \n",
       "50518  PT CRUISER 2.4L I4 S  Lim                  4D SEDAN  ...   \n",
       "50517   MONTERO 4WD V6 3.5L  Lim  4D SPORT UTILITY LIMITED  ...   \n",
       "484     GRAND AM V6 3.4L V6   SE              4D SEDAN SE1  ...   \n",
       "...                     ...  ...                       ...  ...   \n",
       "48619            PT CRUISER  Tou                  4D SEDAN  ...   \n",
       "48620            STRATUS V6  SXT                  4D SEDAN  ...   \n",
       "48621        MALIBU MAXX V6   LS               4D SEDAN LS  ...   \n",
       "50880                  NEON  Bas                  4D SEDAN  ...   \n",
       "21025             MAGNUM V6   SE                WAGON 2.7L  ...   \n",
       "\n",
       "      MMRCurrentRetailAveragePrice MMRCurrentRetailCleanPrice  PRIMEUNIT  \\\n",
       "69724                      11680.0                    13502.0        NaN   \n",
       "50519                       7299.0                     8923.0        NaN   \n",
       "50518                       8126.0                     9545.0        NaN   \n",
       "50517                       8068.0                     9086.0        NaN   \n",
       "484                         3939.0                     5173.0        NaN   \n",
       "...                            ...                        ...        ...   \n",
       "48619                       9005.0                    10247.0        NaN   \n",
       "48620                       7666.0                     8624.0        NaN   \n",
       "48621                       7893.0                     9339.0        NaN   \n",
       "50880                       4310.0                     5078.0        NaN   \n",
       "21025                      13467.0                    15805.0        NaN   \n",
       "\n",
       "      AUCGUART  BYRNO VNZIP1 VNST VehBCost  IsOnlineSale  WarrantyCost  \n",
       "69724      NaN  21053  85226   AZ   9795.0             0          1215  \n",
       "50519      NaN  20833  78219   TX   6150.0             0          1411  \n",
       "50518      NaN  18822  78219   TX   6735.0             0          1086  \n",
       "50517      NaN  18822  78219   TX   7135.0             0          1209  \n",
       "484        NaN  19619  20166   VA   5685.0             0          1666  \n",
       "...        ...    ...    ...  ...      ...           ...           ...  \n",
       "48619      NaN  16044  17545   PA   5785.0             0          1389  \n",
       "48620      NaN  16044  17545   PA   5940.0             0          1389  \n",
       "48621      NaN  16044  17545   PA   7460.0             0          1373  \n",
       "50880      NaN  18822  78219   TX   4135.0             0           986  \n",
       "21025      NaN  17212  75236   TX   8050.0             0          1630  \n",
       "\n",
       "[24104 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>...</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>SATURN</td>\n",
       "      <td>ION</td>\n",
       "      <td>1</td>\n",
       "      <td>4D SEDAN LEVEL 1</td>\n",
       "      <td>...</td>\n",
       "      <td>6658.0</td>\n",
       "      <td>7586.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5546</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20195</th>\n",
       "      <td>20208</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FOCUS</td>\n",
       "      <td>ZX3</td>\n",
       "      <td>2D COUPE ZX3</td>\n",
       "      <td>...</td>\n",
       "      <td>6429.0</td>\n",
       "      <td>7692.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21053</td>\n",
       "      <td>95673</td>\n",
       "      <td>CA</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20194</th>\n",
       "      <td>20207</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>ALTIMA</td>\n",
       "      <td>Bas</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>10167.0</td>\n",
       "      <td>11829.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21053</td>\n",
       "      <td>95673</td>\n",
       "      <td>CA</td>\n",
       "      <td>7605.0</td>\n",
       "      <td>0</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20193</th>\n",
       "      <td>20206</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>MAGNUM V6</td>\n",
       "      <td>SE</td>\n",
       "      <td>WAGON 2.7L</td>\n",
       "      <td>...</td>\n",
       "      <td>13464.0</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21053</td>\n",
       "      <td>95673</td>\n",
       "      <td>CA</td>\n",
       "      <td>9130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>20205</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>1500 RAM PICKUP 2WD</td>\n",
       "      <td>SLT</td>\n",
       "      <td>QUAD CAB 4.7L BIG HORN</td>\n",
       "      <td>...</td>\n",
       "      <td>13781.0</td>\n",
       "      <td>17116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21053</td>\n",
       "      <td>95673</td>\n",
       "      <td>CA</td>\n",
       "      <td>9705.0</td>\n",
       "      <td>0</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68071</th>\n",
       "      <td>68103</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>IMPALA</td>\n",
       "      <td>LT</td>\n",
       "      <td>4D SEDAN LT 3.5L</td>\n",
       "      <td>...</td>\n",
       "      <td>9469.0</td>\n",
       "      <td>11362.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>52598</td>\n",
       "      <td>28273</td>\n",
       "      <td>NC</td>\n",
       "      <td>7570.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70414</th>\n",
       "      <td>70446</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>TRAILBLAZER 2WD 6C</td>\n",
       "      <td>LS</td>\n",
       "      <td>4D SUV 4.2L</td>\n",
       "      <td>...</td>\n",
       "      <td>10507.0</td>\n",
       "      <td>11717.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>20740</td>\n",
       "      <td>32219</td>\n",
       "      <td>FL</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70413</th>\n",
       "      <td>70445</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>ELANTRA</td>\n",
       "      <td>GLS</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>...</td>\n",
       "      <td>6893.0</td>\n",
       "      <td>8131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20740</td>\n",
       "      <td>32219</td>\n",
       "      <td>FL</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>0</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68063</th>\n",
       "      <td>68095</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2006</td>\n",
       "      <td>4</td>\n",
       "      <td>SUZUKI</td>\n",
       "      <td>AERIO</td>\n",
       "      <td>SX</td>\n",
       "      <td>4D WAGON SX</td>\n",
       "      <td>...</td>\n",
       "      <td>7601.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52598</td>\n",
       "      <td>28273</td>\n",
       "      <td>NC</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70420</th>\n",
       "      <td>70452</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>CARAVAN GRAND FWD V6</td>\n",
       "      <td>EX</td>\n",
       "      <td>MINIVAN 3.8L EX</td>\n",
       "      <td>...</td>\n",
       "      <td>6552.0</td>\n",
       "      <td>7319.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>RED</td>\n",
       "      <td>20740</td>\n",
       "      <td>32219</td>\n",
       "      <td>FL</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25820 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RefId  IsBadBuy  PurchDate Auction  VehYear  VehicleAge       Make  \\\n",
       "234      235         0 2010-05-03   ADESA     2005           5     SATURN   \n",
       "20195  20208         0 2010-05-03   OTHER     2004           6       FORD   \n",
       "20194  20207         1 2010-05-03   OTHER     2005           5     NISSAN   \n",
       "20193  20206         0 2010-05-03   OTHER     2007           3      DODGE   \n",
       "20192  20205         0 2010-05-03   OTHER     2007           3      DODGE   \n",
       "...      ...       ...        ...     ...      ...         ...        ...   \n",
       "68071  68103         0 2010-12-30   ADESA     2006           4  CHEVROLET   \n",
       "70414  70446         0 2010-12-30   ADESA     2005           5  CHEVROLET   \n",
       "70413  70445         0 2010-12-30   ADESA     2005           5    HYUNDAI   \n",
       "68063  68095         0 2010-12-30   ADESA     2006           4     SUZUKI   \n",
       "70420  70452         1 2010-12-30   ADESA     2003           7      DODGE   \n",
       "\n",
       "                      Model Trim                SubModel  ...  \\\n",
       "234                     ION    1        4D SEDAN LEVEL 1  ...   \n",
       "20195                 FOCUS  ZX3            2D COUPE ZX3  ...   \n",
       "20194                ALTIMA  Bas                4D SEDAN  ...   \n",
       "20193             MAGNUM V6   SE              WAGON 2.7L  ...   \n",
       "20192   1500 RAM PICKUP 2WD  SLT  QUAD CAB 4.7L BIG HORN  ...   \n",
       "...                     ...  ...                     ...  ...   \n",
       "68071                IMPALA   LT        4D SEDAN LT 3.5L  ...   \n",
       "70414    TRAILBLAZER 2WD 6C   LS             4D SUV 4.2L  ...   \n",
       "70413               ELANTRA  GLS                4D SEDAN  ...   \n",
       "68063                 AERIO   SX             4D WAGON SX  ...   \n",
       "70420  CARAVAN GRAND FWD V6   EX         MINIVAN 3.8L EX  ...   \n",
       "\n",
       "      MMRCurrentRetailAveragePrice MMRCurrentRetailCleanPrice  PRIMEUNIT  \\\n",
       "234                         6658.0                     7586.0        NaN   \n",
       "20195                       6429.0                     7692.0        NaN   \n",
       "20194                      10167.0                    11829.0        NaN   \n",
       "20193                      13464.0                    15661.0        NaN   \n",
       "20192                      13781.0                    17116.0        NaN   \n",
       "...                            ...                        ...        ...   \n",
       "68071                       9469.0                    11362.0         NO   \n",
       "70414                      10507.0                    11717.0         NO   \n",
       "70413                       6893.0                     8131.0        NaN   \n",
       "68063                       7601.0                     8041.0        NaN   \n",
       "70420                       6552.0                     7319.0         NO   \n",
       "\n",
       "      AUCGUART  BYRNO VNZIP1 VNST VehBCost  IsOnlineSale  WarrantyCost  \n",
       "234        NaN   5546  33619   FL   4900.0             0           853  \n",
       "20195      NaN  21053  95673   CA   4990.0             0          1020  \n",
       "20194      NaN  21053  95673   CA   7605.0             0           723  \n",
       "20193      NaN  21053  95673   CA   9130.0             0          1503  \n",
       "20192      NaN  21053  95673   CA   9705.0             0           983  \n",
       "...        ...    ...    ...  ...      ...           ...           ...  \n",
       "68071    GREEN  52598  28273   NC   7570.0             0          1974  \n",
       "70414    GREEN  20740  32219   FL   8200.0             0          1155  \n",
       "70413      NaN  20740  32219   FL   5050.0             0           462  \n",
       "68063      NaN  52598  28273   NC   4500.0             0           983  \n",
       "70420      RED  20740  32219   FL   3800.0             0          2390  \n",
       "\n",
       "[25820 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df, valid_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kA78XfClro-",
    "outputId": "52a5a640-e67b-4015-e491-82e66ad0b069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72983 entries, 0 to 72982\n",
      "Data columns (total 34 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   RefId                              72983 non-null  int64  \n",
      " 1   IsBadBuy                           72983 non-null  int64  \n",
      " 2   PurchDate                          72983 non-null  object \n",
      " 3   Auction                            72983 non-null  object \n",
      " 4   VehYear                            72983 non-null  int64  \n",
      " 5   VehicleAge                         72983 non-null  int64  \n",
      " 6   Make                               72983 non-null  object \n",
      " 7   Model                              72983 non-null  object \n",
      " 8   Trim                               70623 non-null  object \n",
      " 9   SubModel                           72975 non-null  object \n",
      " 10  Color                              72975 non-null  object \n",
      " 11  Transmission                       72974 non-null  object \n",
      " 12  WheelTypeID                        69814 non-null  float64\n",
      " 13  WheelType                          69809 non-null  object \n",
      " 14  VehOdo                             72983 non-null  int64  \n",
      " 15  Nationality                        72978 non-null  object \n",
      " 16  Size                               72978 non-null  object \n",
      " 17  TopThreeAmericanName               72978 non-null  object \n",
      " 18  MMRAcquisitionAuctionAveragePrice  72965 non-null  float64\n",
      " 19  MMRAcquisitionAuctionCleanPrice    72965 non-null  float64\n",
      " 20  MMRAcquisitionRetailAveragePrice   72965 non-null  float64\n",
      " 21  MMRAcquisitonRetailCleanPrice      72965 non-null  float64\n",
      " 22  MMRCurrentAuctionAveragePrice      72668 non-null  float64\n",
      " 23  MMRCurrentAuctionCleanPrice        72668 non-null  float64\n",
      " 24  MMRCurrentRetailAveragePrice       72668 non-null  float64\n",
      " 25  MMRCurrentRetailCleanPrice         72668 non-null  float64\n",
      " 26  PRIMEUNIT                          3419 non-null   object \n",
      " 27  AUCGUART                           3419 non-null   object \n",
      " 28  BYRNO                              72983 non-null  int64  \n",
      " 29  VNZIP1                             72983 non-null  int64  \n",
      " 30  VNST                               72983 non-null  object \n",
      " 31  VehBCost                           72983 non-null  float64\n",
      " 32  IsOnlineSale                       72983 non-null  int64  \n",
      " 33  WarrantyCost                       72983 non-null  int64  \n",
      "dtypes: float64(10), int64(9), object(15)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2L4lcTIp3F0"
   },
   "source": [
    "### - Use LabelEncoder or OneHotEncoder from sklearn to preprocess categorical variables. Be careful with data leakage (fit Encoder to training and apply to validation & test). Consider another coding approach if you encounter new categorical values in validation & test (not seen in training): https://contrib.scikit-learn.org/category_encoders/count.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GzVga9h-gjQ1"
   },
   "outputs": [],
   "source": [
    "TARGET = \"IsBadBuy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7B61X6wYgUh9"
   },
   "outputs": [],
   "source": [
    "drop_cols = [TARGET, \"PurchDate\"]\n",
    "num_cols = train_df.select_dtypes(include=[np.number]).drop(columns=[TARGET], errors=\"ignore\").columns.tolist()\n",
    "num_cols = [c for c in num_cols if c not in drop_cols]\n",
    "cat_cols = [c for c in train_df.columns if c not in num_cols + drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0uC95HQJhRQr",
    "outputId": "a314d1e3-5d24-41e3-9a4e-92466db7a8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовых фич: 18 | Категориальных фич: 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Числовых фич: {len(num_cols)} | Категориальных фич: {len(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iT_nhljxgUfn"
   },
   "outputs": [],
   "source": [
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p09406pNgUdA"
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XVQAf6Zfgx-H"
   },
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\",     ohe)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0bmN9xoAgUai"
   },
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dQWNFiPZgUX8"
   },
   "outputs": [],
   "source": [
    "X_tr = preprocess.fit_transform(train_df)\n",
    "X_va = preprocess.transform(valid_df)\n",
    "X_te = preprocess.transform(test_df)\n",
    "\n",
    "y_tr = train_df[TARGET].to_numpy(dtype=int)\n",
    "y_va = valid_df[TARGET].to_numpy(dtype=int)\n",
    "y_te = test_df[TARGET].to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MdEJ9WggUVh",
    "outputId": "1c3b0440-f291-4325-d6c3-45a5d34a9141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Формы матриц: \n",
      "  X_tr: (23059, 1691) \n",
      "  X_va: (24104, 1691) \n",
      "  X_te: (25820, 1691)\n"
     ]
    }
   ],
   "source": [
    "print(\"Формы матриц:\",\n",
    "      \"\\n  X_tr:\", X_tr.shape,\n",
    "      \"\\n  X_va:\", X_va.shape,\n",
    "      \"\\n  X_te:\", X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRWgnKP2gUQI",
    "outputId": "6e3fcda3-aaf8-4177-ad3b-ba29e4bae9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего признаков после OHE: 1691\n"
     ]
    }
   ],
   "source": [
    "num_names = num_cols\n",
    "ohe_feature_names = preprocess.named_transformers_[\"cat\"].named_steps[\"ohe\"].get_feature_names_out(cat_cols).tolist()\n",
    "feature_names = num_names + ohe_feature_names\n",
    "print(\"Всего признаков после OHE:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihSffEotgUM_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0lQN1jFgT1j"
   },
   "source": [
    "## 2. Create a Python class for Decision Tree Classifier and Decision Tree Regressor (MSE loss).\n",
    "\n",
    "It should support fit, predict_proba, and predict methods. Also, the maximum depth (max_depth) must be a parameter of your class. Use the Gini impurity criterion as a criterion for choosing the split.\n",
    "\n",
    "Here is the blueprint:\n",
    "\n",
    "- model = DecisionTreeClassifier(max_depth=7)\n",
    "- model.fit(Xtrain, ytrain)\n",
    "- model.predict_proba(Xvalid)\n",
    "\n",
    "\n",
    "Create a separate class for Node. It should be able to hold data (sample features and targets), compute Gini impurity, and have pointers to children (left and right nodes). For the Regressor, use standard deviation instead of Gini impurity.\n",
    "Implement a function that finds the best possible split in the current node.\n",
    "Combine the previous steps into your working Decision Tree Classifier.\n",
    "Implement an Extra Randomized Tree by designing another function to find the best split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3kTgfhMciLlx"
   },
   "outputs": [],
   "source": [
    "def gini_from_proba(y_true, y_score):\n",
    "    return 2.0 * roc_auc_score(y_true, y_score) - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=7):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, Xvalid):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, X=None, y=None, depth=0):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.depth = depth\n",
    "\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "        self.is_leaf = False\n",
    "        self.value = None\n",
    "\n",
    "    def gini(self):\n",
    "        if self.y is None or len(self.y) == 0:\n",
    "            return 0.0\n",
    "        _, counts = np.unique(self.y, return_counts=True)\n",
    "        p = counts / counts.sum()\n",
    "        return 1.0 - np.sum(p ** 2)\n",
    "\n",
    "    def variance(self):\n",
    "        if self.y is None or len(self.y) == 0:\n",
    "            return 0.0\n",
    "        return np.var(self.y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth=7,\n",
    "        min_samples_split=2,\n",
    "        max_features=None,\n",
    "        random_state=None,\n",
    "        splitter=\"best\",\n",
    "    ):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.splitter = splitter\n",
    "\n",
    "        self.root_ = None\n",
    "        self.n_features_ = None\n",
    "        self.rng_ = np.random.RandomState(random_state)\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _prepare_target(self, y):\n",
    "        return y\n",
    "\n",
    "    def _get_n_features_to_use(self):\n",
    "        if self.max_features is None:\n",
    "            return self.n_features_\n",
    "        if isinstance(self.max_features, str):\n",
    "            if self.max_features == \"sqrt\":\n",
    "                return max(1, int(np.sqrt(self.n_features_)))\n",
    "            if self.max_features == \"log2\":\n",
    "                return max(1, int(np.log2(self.n_features_)))\n",
    "            # можно добавить другие варианты\n",
    "        if isinstance(self.max_features, int):\n",
    "            return min(self.max_features, self.n_features_)\n",
    "        # fallback\n",
    "        return self.n_features_\n",
    "\n",
    "    def _choose_features(self):\n",
    "        n_feats = self._get_n_features_to_use()\n",
    "        if n_feats == self.n_features_:\n",
    "            return np.arange(self.n_features_)\n",
    "        return self.rng_.choice(self.n_features_, size=n_feats, replace=False)\n",
    "\n",
    "    def _best_split_exhaustive(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        current_impurity = self._impurity(y)\n",
    "        best_impurity = current_impurity\n",
    "\n",
    "        feature_indices = self._choose_features()\n",
    "\n",
    "        n_classes = None\n",
    "        is_classification = False\n",
    "\n",
    "        if y.dtype == int or y.dtype == np.int64 or y.dtype == np.int32:\n",
    "            unique_classes = np.unique(y)\n",
    "            if np.array_equal(unique_classes, np.array([0, 1])) or len(unique_classes) <= 10:\n",
    "                is_classification = True\n",
    "                n_classes = len(unique_classes)\n",
    "\n",
    "        for feature in feature_indices:\n",
    "            Xj = X[:, feature]\n",
    "            sorted_idx = np.argsort(Xj)\n",
    "            x_sorted = Xj[sorted_idx]\n",
    "            y_sorted = y[sorted_idx]\n",
    "\n",
    "            if x_sorted[0] == x_sorted[-1]:\n",
    "                continue\n",
    "\n",
    "            if is_classification:\n",
    "                unique_classes = np.unique(y_sorted)\n",
    "                class_to_index = {c: i for i, c in enumerate(unique_classes)}\n",
    "                total_counts = np.bincount(\n",
    "                    [class_to_index[c] for c in y_sorted],\n",
    "                    minlength=len(unique_classes),\n",
    "                ).astype(float)\n",
    "\n",
    "                left_counts = np.zeros_like(total_counts)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            for i in range(1, m):\n",
    "                if is_classification:\n",
    "                    c = class_to_index[y_sorted[i - 1]]\n",
    "                    left_counts[c] += 1\n",
    "                    right_counts = total_counts - left_counts\n",
    "\n",
    "                    if x_sorted[i] == x_sorted[i - 1]:\n",
    "                        continue\n",
    "\n",
    "                    left_n = i\n",
    "                    right_n = m - i\n",
    "                    if left_n == 0 or right_n == 0:\n",
    "                        continue\n",
    "\n",
    "                    p_left = left_counts / left_n\n",
    "                    p_right = right_counts / right_n\n",
    "\n",
    "                    gini_left = 1.0 - np.sum(p_left ** 2)\n",
    "                    gini_right = 1.0 - np.sum(p_right ** 2)\n",
    "\n",
    "                    impurity = (left_n / m) * gini_left + (right_n / m) * gini_right\n",
    "                else:\n",
    "                    if x_sorted[i] == x_sorted[i - 1]:\n",
    "                        continue\n",
    "                    thr = (x_sorted[i] + x_sorted[i - 1]) / 2.0\n",
    "                    left_mask = Xj <= thr\n",
    "                    right_mask = ~left_mask\n",
    "                    if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "                        continue\n",
    "                    y_left = y[left_mask]\n",
    "                    y_right = y[right_mask]\n",
    "                    impurity = (\n",
    "                        len(y_left) / m * self._impurity(y_left)\n",
    "                        + len(y_right) / m * self._impurity(y_right)\n",
    "                    )\n",
    "\n",
    "                if impurity < best_impurity:\n",
    "                    best_impurity = impurity\n",
    "                    best_feature = feature\n",
    "                    if is_classification:\n",
    "                        best_threshold = (x_sorted[i] + x_sorted[i - 1]) / 2.0\n",
    "                    else:\n",
    "                        best_threshold = thr\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _best_split_random(self, X, y, n_thresholds=1):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_impurity = self._impurity(y)\n",
    "\n",
    "        feature_indices = self._choose_features()\n",
    "\n",
    "        for feature in feature_indices:\n",
    "            Xj = X[:, feature]\n",
    "            xmin, xmax = Xj.min(), Xj.max()\n",
    "            if xmin == xmax:\n",
    "                continue\n",
    "\n",
    "            for _ in range(n_thresholds):\n",
    "                thr = self.rng_.uniform(xmin, xmax)\n",
    "                left_mask = Xj <= thr\n",
    "                right_mask = ~left_mask\n",
    "                if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "                    continue\n",
    "                y_left = y[left_mask]\n",
    "                y_right = y[right_mask]\n",
    "                impurity = (\n",
    "                    len(y_left) / m * self._impurity(y_left)\n",
    "                    + len(y_right) / m * self._impurity(y_right)\n",
    "                )\n",
    "                if impurity < best_impurity:\n",
    "                    best_impurity = impurity\n",
    "                    best_feature = feature\n",
    "                    best_threshold = thr\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        if self.splitter == \"random\":\n",
    "            return self._best_split_random(X, y)\n",
    "        return self._best_split_exhaustive(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        node = Node(X=X, y=y, depth=depth)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or n_samples < self.min_samples_split\n",
    "            or self._impurity(y) == 0.0\n",
    "        ):\n",
    "            node.is_leaf = True\n",
    "            node.value = self._leaf_value(y)\n",
    "            node.X = None\n",
    "            node.y = None\n",
    "            return node\n",
    "\n",
    "        feature, threshold = self._best_split(X, y)\n",
    "        if feature is None:\n",
    "            node.is_leaf = True\n",
    "            node.value = self._leaf_value(y)\n",
    "            node.X = None\n",
    "            node.y = None\n",
    "            return node\n",
    "\n",
    "        Xj = X[:, feature]\n",
    "        left_mask = Xj <= threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "            node.is_leaf = True\n",
    "            node.value = self._leaf_value(y)\n",
    "            node.X = None\n",
    "            node.y = None\n",
    "            return node\n",
    "\n",
    "        node.feature_index = feature\n",
    "        node.threshold = threshold\n",
    "        node.is_leaf = False\n",
    "\n",
    "        node.left = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        node.right = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        node.X = None\n",
    "        node.y = None\n",
    "        return node\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        self.n_features_ = X.shape[1]\n",
    "        y = self._prepare_target(y)\n",
    "        self.root_ = self._build_tree(X, y, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _predict_one(self, x, node):\n",
    "        while not node.is_leaf:\n",
    "            if x[node.feature_index] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.value\n",
    "\n",
    "    def _predict_raw(self, X):\n",
    "        X = np.asarray(X)\n",
    "        preds = [self._predict_one(x, self.root_) for x in X]\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(BaseDecisionTree):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth=7,\n",
    "        min_samples_split=2,\n",
    "        max_features=None,\n",
    "        random_state=None,\n",
    "        splitter=\"best\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state,\n",
    "            splitter=splitter,\n",
    "        )\n",
    "        self.n_classes_ = None\n",
    "\n",
    "    def _prepare_target(self, y):\n",
    "        y = np.asarray(y, dtype=int)\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p = counts / counts.sum()\n",
    "        return 1.0 - np.sum(p ** 2)\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        if len(y) == 0:\n",
    "            return np.ones(self.n_classes_) / self.n_classes_\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        proba = np.zeros(self.n_classes_, dtype=float)\n",
    "        for cls, cnt in zip(_, counts):\n",
    "            idx = np.where(self.classes_ == cls)[0][0]\n",
    "            proba[idx] = cnt\n",
    "        proba = proba / proba.sum()\n",
    "        return proba\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        raw = self._predict_raw(X)\n",
    "        return raw\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        class_indices = np.argmax(proba, axis=1)\n",
    "        return self.classes_[class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor(BaseDecisionTree):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth=7,\n",
    "        min_samples_split=2,\n",
    "        max_features=None,\n",
    "        random_state=None,\n",
    "        splitter=\"best\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state,\n",
    "            splitter=splitter,\n",
    "        )\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        return np.var(y)\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0.0\n",
    "        return float(np.mean(y))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._predict_raw(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtraRandomTreeClassifier(DecisionTreeClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth=7,\n",
    "        min_samples_split=2,\n",
    "        max_features=None,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state,\n",
    "            splitter=\"random\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_my = DecisionTreeClassifier(\n",
    "    max_depth=7,\n",
    "    min_samples_split=50,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_my.fit(X_tr, y_tr)\n",
    "proba_va_my = tree_my.predict_proba(X_va)[:, 1]\n",
    "gini_va_my = gini_from_proba(y_va, proba_va_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. With your DecisionTree module, you must obtain a Gini score of at least 0.1 on the validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini valid (my DecisionTree): 0.25825970261391507\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini valid (my DecisionTree):\", gini_va_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use sklearn's DecisionTreeClassifier and check its performance on the validation dataset. Is it better than your module? If so, why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_tree = SkDecisionTreeClassifier(\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    criterion=\"gini\",\n",
    ")\n",
    "sk_tree.fit(X_tr, y_tr)\n",
    "proba_va_sk = sk_tree.predict_proba(X_va)[:, 1]\n",
    "gini_va_sk = gini_from_proba(y_va, proba_va_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini valid (sklearn DecisionTree): 0.25390753187689485\n",
      "Gini valid (my DecisionTree):      0.25825970261391507\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini valid (sklearn DecisionTree):\", gini_va_sk)\n",
    "print(\"Gini valid (my DecisionTree):     \", gini_va_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sklearn имеет больше оптимизаций (best-first split, pruning options), но также более склонен к переобучению.\n",
    "- Мой вариант более регуляризован за счёт min_samples_split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement the RandomForestClassifier and check its performance. You have to improve the result of a single tree and get at least 0.15 Gini score on the validation dataset. Be able to set a fixed random seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=50,\n",
    "        max_depth=7,\n",
    "        min_samples_split=2,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=True,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.trees_ = []\n",
    "        self.rng_ = np.random.RandomState(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        n_samples = X.shape[0]\n",
    "        self.trees_ = []\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = self.rng_.choice(n_samples, size=n_samples, replace=True)\n",
    "            else:\n",
    "                indices = np.arange(n_samples)\n",
    "\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_features=self.max_features,\n",
    "                random_state=self.rng_.randint(0, 1_000_000),\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # усредняем вероятности\n",
    "        probs = [tree.predict_proba(X) for tree in self.trees_]\n",
    "        probs = np.stack(probs, axis=0)  # (n_trees, n_samples, n_classes)\n",
    "        return probs.mean(axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_my = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=7,\n",
    "    min_samples_split=50,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_my.fit(X_tr, y_tr)\n",
    "proba_va_rf = rf_my.predict_proba(X_va)[:, 1]\n",
    "gini_va_rf = gini_from_proba(y_va, proba_va_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini valid (my RandomForest): 0.31788273884363005\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini valid (my RandomForest):\", gini_va_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use your DecisionTree design class for GBDT classifier. This class must have max_depth, number_of_trees and max_features attributes. You must compute the gradient of the binary cross-entropy loss function and implement incremental learning: train the next tree using the results of the previous trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDTClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=50,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        max_features=None,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.trees_ = []\n",
    "        self.f0_ = None\n",
    "        self.rng_ = np.random.RandomState(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        # защита от p=0 или p=1\n",
    "        p = np.clip(y.mean(), 1e-5, 1.0 - 1e-5)\n",
    "        self.f0_ = np.log(p / (1.0 - p))\n",
    "\n",
    "        F = np.full_like(y, fill_value=self.f0_, dtype=float)\n",
    "\n",
    "        self.trees_ = []\n",
    "\n",
    "        for m in range(self.n_estimators):\n",
    "            p_hat = _sigmoid(F)\n",
    "            residual = y - p_hat\n",
    "\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=20,\n",
    "                max_features=self.max_features,\n",
    "                random_state=self.rng_.randint(0, 1_000_000),\n",
    "            )\n",
    "            tree.fit(X, residual)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "            update = tree.predict(X)\n",
    "            F += self.learning_rate * update\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _raw_score(self, X):\n",
    "        X = np.asarray(X)\n",
    "        F = np.full(X.shape[0], self.f0_, dtype=float)\n",
    "        for tree in self.trees_:\n",
    "            F += self.learning_rate * tree.predict(X)\n",
    "        return F\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return _sigmoid(self._raw_score(X))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GBDTClassifier(\n",
    "    n_estimators=80,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    max_features=200,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(X_tr, y_tr)\n",
    "\n",
    "p_va = gb.predict_proba(X_va)\n",
    "gini_va = gini_from_proba(y_va, p_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT custom Gini valid: 0.32775444077586036\n"
     ]
    }
   ],
   "source": [
    "print(\"GBDT custom Gini valid:\", gini_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use LightGBM, Catboost, and XGBoost for fitting on a training set and prediction on a validation set. Review the documentation of the libraries and fine-tune the algorithms for the task. Note key differences between each implementation. Analyze special features of each algorithm (how does \"categorical feature\" work in Catboost, what is DART mode in XGBoost)? Which GBDT model gives the best result? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lgb = lgb.Dataset(X_tr, y_tr)\n",
    "valid_lgb = lgb.Dataset(X_va, y_va, reference=train_lgb)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'max_depth': -1,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2607, number of negative: 20452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4011\n",
      "[LightGBM] [Info] Number of data points in the train set: 23059, number of used features: 431\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.113058 -> initscore=-2.059881\n",
      "[LightGBM] [Info] Start training from score -2.059881\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.683507\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.684162\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.train(\n",
    "    params,\n",
    "    train_lgb,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[valid_lgb],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),\n",
    "        lgb.log_evaluation(period=100),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Gini: 0.36832377927593263\n"
     ]
    }
   ],
   "source": [
    "p_lgb = model_lgb.predict(X_va)\n",
    "print(\"LightGBM Gini:\", gini_from_proba(y_va, p_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5586486\tbest: 0.5586486 (0)\ttotal: 61.1ms\tremaining: 2m 2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6747982098\n",
      "bestIteration = 112\n",
      "\n",
      "Shrink model to first 113 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x11fa9e660>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cb = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3,\n",
    "    iterations=2000,\n",
    "    random_seed=42,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=50,\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "model_cb.fit(X_tr, y_tr, eval_set=(X_va, y_va), use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost (на OHE) Gini: 0.3495964196643968\n"
     ]
    }
   ],
   "source": [
    "p_cb = model_cb.predict_proba(X_va)[:, 1]\n",
    "print(\"CatBoost (на OHE) Gini:\", gini_from_proba(y_va, p_cb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_df[cat_cols + num_cols].copy()\n",
    "valid_raw = valid_df[cat_cols + num_cols].copy()\n",
    "y_tr_raw = train_df[TARGET]\n",
    "y_va_raw = valid_df[TARGET]\n",
    "for c in cat_cols:\n",
    "    train_raw[c] = train_raw[c].astype(str).fillna(\"Unknown\")\n",
    "    valid_raw[c] = valid_raw[c].astype(str).fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [train_raw.columns.get_loc(c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6345821\tbest: 0.6345821 (0)\ttotal: 9.59ms\tremaining: 19.2s\n",
      "200:\ttest: 0.7466426\tbest: 0.7468666 (184)\ttotal: 2.8s\tremaining: 25.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.747184753\n",
      "bestIteration = 225\n",
      "\n",
      "Shrink model to first 226 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x128235810>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3,\n",
    "    iterations=2000,\n",
    "    random_seed=42,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=50,\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "cat_model.fit(\n",
    "    train_raw,\n",
    "    y_tr_raw,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(valid_raw, y_va_raw),\n",
    "    use_best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost (raw categories) Gini: 0.494369506077168\n"
     ]
    }
   ],
   "source": [
    "pred_cat = cat_model.predict_proba(valid_raw)[:, 1]\n",
    "print(\"CatBoost (raw categories) Gini:\", gini_from_proba(y_va_raw, pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-auc:0.62462\n",
      "[100]\tvalid-auc:0.68656\n",
      "[200]\tvalid-auc:0.68934\n",
      "[300]\tvalid-auc:0.69191\n",
      "[400]\tvalid-auc:0.69058\n",
      "[427]\tvalid-auc:0.69066\n"
     ]
    }
   ],
   "source": [
    "train_xgb = xgb.DMatrix(X_tr, label=y_tr)\n",
    "valid_xgb = xgb.DMatrix(X_va, label=y_va)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 7,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'lambda': 1.0,\n",
    "    'alpha': 0.0,\n",
    "    'tree_method': 'hist',\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "model_xgb = xgb.train(\n",
    "    params,\n",
    "    train_xgb,\n",
    "    num_boost_round=2000,\n",
    "    evals=[(valid_xgb, 'valid')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Gini: 0.38132212511944164\n"
     ]
    }
   ],
   "source": [
    "p_xgb = model_xgb.predict(valid_xgb)\n",
    "print(\"XGBoost Gini:\", gini_from_proba(y_va, p_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost**\n",
    "\n",
    "- Умеет работать с категориальными признаками без One-Hot Encoding.\n",
    "\n",
    "- Использует target-based encoding, но делает это безопасно через Ordered Boosting — каждая строка кодируется только по предыдущим объектам - нет data leakage.\n",
    "\n",
    "- Автоматически создаёт комбинации категориальных признаков (feature combinations), что особенно важно для автомобильных данных (Make + Model + Trim + SubModel).\n",
    "\n",
    "- Учитывает частоту категории, её условное среднее по таргету, и историю появления — даёт богатое статистическое представление вместо тысячи OHE-признаков.\n",
    "\n",
    "- Обрабатывает редкие категории корректно (не проваливается, как OHE - sparse matrix).\n",
    "\n",
    "- Для задач, где много категориальных признаков, CatBoost обычно показывает лучшее качество, чем LightGBM/XGBoost, при работе с сырыми данными.\n",
    "\n",
    "Поэтому при работе с raw categories (без OHE) CatBoost дал самый высокий Gini ≈ 0.49.\n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "- Классический градиентный бустинг с точным поиском сплитов (exact greedy).\n",
    "\n",
    "- Имеет режим DART (Dropouts meet Boosting) - случайно “выключает” некоторые деревья при обучении, как в dropout у нейросетей - снижает переобучение.\n",
    "\n",
    "- Очень хорошо работает с разреженными матрицами после OHE.\n",
    "\n",
    "**LightGBM**\n",
    "\n",
    "- Использует histogram-based обучение и leaf-wise рост деревьев - быстрее, глубже и эффективнее на больших данных.\n",
    "\n",
    "- Отлично подходит для разреженных OHE-признаков.\n",
    "\n",
    "- Поддерживает фичи вроде GOSS и EFB, уменьшающие вычислительную нагрузку.\n",
    "\n",
    "**Какая модель дала лучший результат?**\n",
    "\n",
    "Если использовать OHE, как в стандартном pipeline:\n",
    "- XGBoost показывает наилучший Gini (≈ 0.38).\n",
    "\n",
    "Если использовать сырые категориальные признаки (как задумано для CatBoost):\n",
    "- CatBoost становится лучшей моделью с огромным отрывом (Gini ≈ 0.49).\n",
    "\n",
    "\n",
    "**Почему CatBoost стал лучшим (если не использовать OHE)?**\n",
    "\n",
    "1. Он использует нативную обработку категорий, где каждая категория превращается в мощный статистический признак (conditional target mean).\n",
    "\n",
    "2. Он автоматически строит комбинации категориальных признаков, которые критически важны для данных о машинах:\n",
    "\n",
    "- Make + Model\n",
    "\n",
    "- Model + Trim\n",
    "\n",
    "- Color + SubModel\n",
    "\n",
    "3. Не разрывает информацию на тысячи бинарных OHE-фичей.\n",
    "\n",
    "4. Избегает переобучения благодаря Ordered Boosting.\n",
    "\n",
    "5. Умеет работать с редкими категориями без деградации качества.\n",
    "\n",
    "Поэтому качество CatBoost выросло с 0.35 (на OHE) до 0.49 (на raw categories).\n",
    "\n",
    "**Почему XGBoost лучше с OHE?**\n",
    "\n",
    "1. Данные после OHE - сильно разреженные. XGBoost особенно эффективен с такими матрицами.\n",
    "\n",
    "2. Использует точные сплиты, которые лучше работают с множеством редких категорий.\n",
    "\n",
    "3. Устойчив к дисбалансу классов и шуму.\n",
    "\n",
    "4. LightGBM теряет немного точности из-за гистограммного приближения, а CatBoost - потому что его преимущество исчезает при OHE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Take the best model and estimate its performance on the test dataset: check the Gini values on all three datasets for your best model: training Gini, valid Gini, test Gini. Do you see a drop in performance when comparing the valid quality to the test quality? Is your model overfitting or not? Explain.\n",
    "\n",
    "В качестве лучшей модели был выбран XGBoost, показавший максимальное качество на валидационной выборке.\n",
    "\n",
    "Результаты (Gini):\n",
    "\n",
    "- Train Gini: 0.712\n",
    "\n",
    "- Valid Gini: 0.374\n",
    "\n",
    "- Test Gini: 0.377\n",
    "\n",
    "Анализ:\n",
    "\n",
    "1. Train Gini значительно выше, чем valid/test (0.71 vs 0.37).\n",
    "Это нормально для бустинга — тренировочные деревья подгоняются под данные сильнее.\n",
    "\n",
    "2. Valid и Test Gini почти одинаковые (0.374 vs 0.377).\n",
    "Разница составляет менее 0.003, что означает:\n",
    "\n",
    "- модель не переобучена на валидацию,\n",
    "\n",
    "- модель стабильно обобщает на новых данных.\n",
    "\n",
    "3. Легкий рост качества на тесте по сравнению с валидацией объясняется тем, что:\n",
    "\n",
    "- тестовая выборка содержит близкое распределение дат и категорий,\n",
    "\n",
    "- модель была остановлена ранней остановкой (early stopping), предотвращая переобучение,\n",
    "\n",
    "- деревья имеют ограниченную глубину, много регуляризации (subsample, colsample_bytree, min_child_weight).\n",
    "\n",
    "Вывод:\n",
    "\n",
    "- Модель не переобучена: качество на тестовой выборке практически совпадает с валидацией.\n",
    "\n",
    "- XGBoost показал устойчивое качество и является лучшей моделью для данного набора данных.\n",
    "\n",
    "\n",
    "**Градиентный бустинг ВСЕГДА сильно подгоняет train**\n",
    "\n",
    "XGBoost обучается последовательно, исправляя ошибки предыдущих деревьев - в итоге он способен очень сильно увеличить качество на обучении.\n",
    "\n",
    "У XGBoost:\n",
    "\n",
    "- Train Gini 0.7+ — нормальное поведение.\n",
    "\n",
    "Он докручивает границу решения до максимума, который позволяет модель.\n",
    "\n",
    "Это не считается переобучением само по себе.\n",
    "\n",
    "**Дополнительный эксперимент: CatBoost без OHE (RAW categories)**\n",
    "\n",
    "CatBoost обучался на исходных категориальных признаках, без One-Hot Encoding, с указанием cat_features.\n",
    "\n",
    "CatBoost применяет:\n",
    "\n",
    "- ordered target encoding (без утечки по данным),\n",
    "\n",
    "- автоматическое построение комбинаций категорий,\n",
    "\n",
    "- оптимизированную обработку редких и частых категорий.\n",
    "\n",
    "Это дало существенный прирост качества.\n",
    "\n",
    "Результаты CatBoost (RAW categories):\n",
    "Датасет\tGini\n",
    "Train\t0.622\n",
    "Valid\t0.494\n",
    "Test\t0.409\n",
    "\n",
    "Анализ CatBoost:\n",
    "\n",
    "+ Valid Gini = 0.494 — существенно выше, чем у XGBoost.\n",
    "\n",
    "+ Test Gini = 0.409 также заметно выше XGBoost (0.374).\n",
    "\n",
    "+ Train Gini ниже, чем у XGBoost — что указывает на меньшую склонность CatBoost к переобучению.\n",
    "\n",
    "+ CatBoost лучше раскрывает категориальные признаки, не превращая их в 1700+ sparse-фич, как OHE.\n",
    "\n",
    "Вывод по CatBoost:\n",
    "\n",
    "- CatBoost, обученный на сырых категориальных данных, показал наилучшее качество среди всех моделей.\n",
    "Это подтверждает его преимущество в задачах с большим количеством категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "dvalid = xgb.DMatrix(X_va, label=y_va)\n",
    "dtest  = xgb.DMatrix(X_te, label=y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tr = model_xgb.predict(dtrain)\n",
    "p_va = model_xgb.predict(dvalid)\n",
    "p_te = model_xgb.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== XGBoost Gini Scores ====\n",
      "Train Gini: 0.853325\n",
      "Valid Gini: 0.381322\n",
      "Test  Gini: 0.374259\n"
     ]
    }
   ],
   "source": [
    "gini_tr = gini_from_proba(y_tr, p_tr)\n",
    "gini_va = gini_from_proba(y_va, p_va)\n",
    "gini_te = gini_from_proba(y_te, p_te)\n",
    "\n",
    "print(\"==== XGBoost Gini Scores ====\")\n",
    "print(f\"Train Gini: {gini_tr:.6f}\")\n",
    "print(f\"Valid Gini: {gini_va:.6f}\")\n",
    "print(f\"Test  Gini: {gini_te:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr_cb = cat_model.predict_proba(train_raw)[:, 1]\n",
    "pred_va_cb = cat_model.predict_proba(valid_raw)[:, 1]\n",
    "pred_te_cb = cat_model.predict_proba(test_df[cat_cols + num_cols]\n",
    "                                     .assign(**{c: lambda df: df[c].astype(str).fillna(\"Unknown\") \n",
    "                                                for c in cat_cols}))[:, 1]\n",
    "\n",
    "gini_tr_cb = gini_from_proba(y_tr_raw, pred_tr_cb)\n",
    "gini_va_cb = gini_from_proba(y_va_raw, pred_va_cb)\n",
    "gini_te_cb = gini_from_proba(y_te, pred_te_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost RAW CATEGORIES\n",
      " Train Gini: 0.6216021556850468\n",
      " Valid Gini: 0.494369506077168\n",
      " Test  Gini: 0.40914571877268635\n"
     ]
    }
   ],
   "source": [
    "print(\"CatBoost RAW CATEGORIES\")\n",
    "print(\" Train Gini:\", gini_tr_cb)\n",
    "print(\" Valid Gini:\", gini_va_cb)\n",
    "print(\" Test  Gini:\", gini_te_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model  Train Gini  Valid Gini  Test Gini\n",
      "0              XGBoost (OHE)    0.853325    0.381322   0.374259\n",
      "1  CatBoost (RAW categories)    0.621602    0.494370   0.409146\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"XGBoost (OHE)\", \"CatBoost (RAW categories)\"],\n",
    "    \"Train Gini\": [gini_tr, gini_tr_cb],\n",
    "    \"Valid Gini\": [gini_va, gini_va_cb],\n",
    "    \"Test Gini\":  [gini_te, gini_te_cb],\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9*. Implement the ExtraTreesClassifier and check its performance. You must improve the result of a single tree and obtain a Gini score of at least 0.12 on the validation dataset.\n",
    "\n",
    "*BONUSE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PASS**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5FKBqs7dZcUQ",
    "9ImMBoHGZe6s",
    "M2L4lcTIp3F0",
    "72bRV0BZqAI-",
    "w8VkyHiaqFqb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python ML-env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
